{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import backend as K\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "TEST_SIZE = 150000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df = pd.read_csv(\n",
    "            \"../input/train.csv\",\n",
    "            names=[\"x\", \"y\"],\n",
    "            skiprows=1,\n",
    "            dtype={\"x\": \"float32\", \"y\": \"float32\"}\n",
    "        )\n",
    "    return df\n",
    "BIG_FRAME = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_case():\n",
    "    data = BIG_FRAME.values\n",
    "    max_start = len(data) - TEST_SIZE + 1\n",
    "    while True:\n",
    "        start = np.random.randint(max_start)\n",
    "        end = start + TEST_SIZE\n",
    "        if data[start, 1] < data[end - 1, 1]:\n",
    "            continue  \n",
    "        yield data[start:end, :1], data[end - 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_batch(batch_size=16):\n",
    "    while True:\n",
    "        x_batch = np.zeros((batch_size, TEST_SIZE, 1))\n",
    "        y_batch = np.zeros((batch_size, ))\n",
    "        gen = yield_case()\n",
    "        for i, (x, y) in zip(range(batch_size), gen):\n",
    "            x_batch[i] = x\n",
    "            y_batch[i] = y\n",
    "        yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def primes(num=TEST_SIZE):\n",
    "    d = 2\n",
    "    rez = []\n",
    "    while num > 1:\n",
    "        full, rem = divmod(num, d)\n",
    "        if not rem:\n",
    "            rez.append(d)\n",
    "            num = full\n",
    "        else:\n",
    "            d += 1\n",
    "    for i in sorted(rez, reverse=True):\n",
    "        yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "def make_model(filters):\n",
    "    K.clear_session()\n",
    "    y = x = layers.Input(shape=(TEST_SIZE, 1))\n",
    "    \n",
    "    # Pad at start\n",
    "    y = layers.Lambda(\n",
    "            lambda x: x[:, -1::-1, :], output_shape=(TEST_SIZE, 1))(y)\n",
    "    \n",
    "    y = layers.Conv1D(\n",
    "            filters=filters,\n",
    "            kernel_size=1,\n",
    "            strides=1,\n",
    "            activation=None)(y)\n",
    "    \n",
    "    skips = []\n",
    "    for kernel_size in range(int(np.log(TEST_SIZE) / np.log(2)) + 1):\n",
    "        y_rez = layers.AveragePooling1D(\n",
    "            pool_size=1,\n",
    "            strides=2,\n",
    "            padding=\"same\"\n",
    "        )(y)\n",
    "        y_f = layers.Conv1D(\n",
    "            filters=filters,\n",
    "            kernel_size=2,\n",
    "            strides=2,\n",
    "            padding=\"same\",\n",
    "            activation=\"tanh\")(y)   # Try ReLu\n",
    "        y_g = layers.Conv1D(\n",
    "            filters=filters,\n",
    "            kernel_size=2,\n",
    "            strides=2,\n",
    "            padding=\"same\",\n",
    "            activation=\"sigmoid\")(y)\n",
    "        y = layers.Multiply()([y_f, y_g])\n",
    "        y_skip = layers.Conv1D(\n",
    "            filters=filters,\n",
    "            kernel_size=1,\n",
    "            strides=1,\n",
    "            activation=None)(y)\n",
    "        y_skip = layers.Lambda(\n",
    "            lambda x: x[:, -1:, :], output_shape=(1, filters))(y_skip)\n",
    "        skips.append(y_skip)\n",
    "        y = layers.Conv1D(\n",
    "            filters=filters,\n",
    "            kernel_size=1,\n",
    "            strides=1,\n",
    "            activation=None)(y)\n",
    "        y = layers.Add()([y_rez, y])\n",
    "        \n",
    "    y = layers.Add()(skips)\n",
    "    y = layers.Activation(\"relu\")(y)\n",
    "    y = layers.Conv1D(\n",
    "            filters=filters,\n",
    "            kernel_size=1,\n",
    "            strides=1,\n",
    "            activation=\"relu\")(y)\n",
    "    y = layers.Conv1D(\n",
    "            filters=1,\n",
    "            kernel_size=1,\n",
    "            strides=1,\n",
    "            activation=\"relu\")(y)\n",
    "    y = layers.Flatten()(y)\n",
    "\n",
    "    model = models.Model(inputs=x, outputs=y)\n",
    "    model.compile(optimizer=optimizers.Nadam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004),\n",
    "                  loss='mean_absolute_error',\n",
    "                  # metrics=['mean_absolute_error']\n",
    "    )\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(filters, batch_size, epochs=100):\n",
    "    model = make_model(filters)\n",
    "    steps = 600 * 10 ** 6 // TEST_SIZE // batch_size\n",
    "    cb = [\n",
    "        callbacks.ModelCheckpoint(\"model_conv.h5\", monitor=\"loss\", verbose=1, save_best_only=True),\n",
    "        callbacks.EarlyStopping(monitor='loss', patience=epochs // 10, verbose=10)\n",
    "    ]\n",
    "    rez = model.fit_generator(\n",
    "        yield_batch(batch_size),\n",
    "        steps_per_epoch=steps,\n",
    "        epochs=epochs,\n",
    "        callbacks=cb\n",
    "    )\n",
    "    return rez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 150000, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 150000, 1)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 150000, 128)  256         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 75000, 128)   32896       conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 75000, 128)   32896       conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 75000, 128)   0           conv1d_2[0][0]                   \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_1 (AveragePoo (None, 75000, 128)   0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 75000, 128)   16512       multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 75000, 128)   0           average_pooling1d_1[0][0]        \n",
      "                                                                 conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 37500, 128)   32896       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 37500, 128)   32896       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 37500, 128)   0           conv1d_6[0][0]                   \n",
      "                                                                 conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_2 (AveragePoo (None, 37500, 128)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 37500, 128)   16512       multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 37500, 128)   0           average_pooling1d_2[0][0]        \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 18750, 128)   32896       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 18750, 128)   32896       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 18750, 128)   0           conv1d_10[0][0]                  \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_3 (AveragePoo (None, 18750, 128)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 18750, 128)   16512       multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 18750, 128)   0           average_pooling1d_3[0][0]        \n",
      "                                                                 conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 9375, 128)    32896       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 9375, 128)    32896       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 9375, 128)    0           conv1d_14[0][0]                  \n",
      "                                                                 conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_4 (AveragePoo (None, 9375, 128)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 9375, 128)    16512       multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 9375, 128)    0           average_pooling1d_4[0][0]        \n",
      "                                                                 conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 4688, 128)    32896       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 4688, 128)    32896       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 4688, 128)    0           conv1d_18[0][0]                  \n",
      "                                                                 conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_5 (AveragePoo (None, 4688, 128)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 4688, 128)    16512       multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 4688, 128)    0           average_pooling1d_5[0][0]        \n",
      "                                                                 conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 2344, 128)    32896       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 2344, 128)    32896       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 2344, 128)    0           conv1d_22[0][0]                  \n",
      "                                                                 conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_6 (AveragePoo (None, 2344, 128)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 2344, 128)    16512       multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 2344, 128)    0           average_pooling1d_6[0][0]        \n",
      "                                                                 conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 1172, 128)    32896       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 1172, 128)    32896       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 1172, 128)    0           conv1d_26[0][0]                  \n",
      "                                                                 conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_7 (AveragePoo (None, 1172, 128)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 1172, 128)    16512       multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 1172, 128)    0           average_pooling1d_7[0][0]        \n",
      "                                                                 conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 586, 128)     32896       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 586, 128)     32896       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 586, 128)     0           conv1d_30[0][0]                  \n",
      "                                                                 conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_8 (AveragePoo (None, 586, 128)     0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 586, 128)     16512       multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 586, 128)     0           average_pooling1d_8[0][0]        \n",
      "                                                                 conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 293, 128)     32896       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 293, 128)     32896       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 293, 128)     0           conv1d_34[0][0]                  \n",
      "                                                                 conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_9 (AveragePoo (None, 293, 128)     0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 293, 128)     16512       multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 293, 128)     0           average_pooling1d_9[0][0]        \n",
      "                                                                 conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 147, 128)     32896       add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 147, 128)     32896       add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 147, 128)     0           conv1d_38[0][0]                  \n",
      "                                                                 conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_10 (AveragePo (None, 147, 128)     0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 147, 128)     16512       multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 147, 128)     0           average_pooling1d_10[0][0]       \n",
      "                                                                 conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 74, 128)      32896       add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 74, 128)      32896       add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 74, 128)      0           conv1d_42[0][0]                  \n",
      "                                                                 conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_11 (AveragePo (None, 74, 128)      0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 74, 128)      16512       multiply_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 74, 128)      0           average_pooling1d_11[0][0]       \n",
      "                                                                 conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 37, 128)      32896       add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 37, 128)      32896       add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 37, 128)      0           conv1d_46[0][0]                  \n",
      "                                                                 conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_12 (AveragePo (None, 37, 128)      0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 37, 128)      16512       multiply_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 37, 128)      0           average_pooling1d_12[0][0]       \n",
      "                                                                 conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 19, 128)      32896       add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 19, 128)      32896       add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 19, 128)      0           conv1d_50[0][0]                  \n",
      "                                                                 conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_13 (AveragePo (None, 19, 128)      0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 19, 128)      16512       multiply_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 19, 128)      0           average_pooling1d_13[0][0]       \n",
      "                                                                 conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 10, 128)      32896       add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 10, 128)      32896       add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)          (None, 10, 128)      0           conv1d_54[0][0]                  \n",
      "                                                                 conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_14 (AveragePo (None, 10, 128)      0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 10, 128)      16512       multiply_14[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 10, 128)      0           average_pooling1d_14[0][0]       \n",
      "                                                                 conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 5, 128)       32896       add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 5, 128)       32896       add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)          (None, 5, 128)       0           conv1d_58[0][0]                  \n",
      "                                                                 conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_15 (AveragePo (None, 5, 128)       0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 5, 128)       16512       multiply_15[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 5, 128)       0           average_pooling1d_15[0][0]       \n",
      "                                                                 conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 3, 128)       32896       add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 3, 128)       32896       add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 3, 128)       0           conv1d_62[0][0]                  \n",
      "                                                                 conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_16 (AveragePo (None, 3, 128)       0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 3, 128)       16512       multiply_16[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 3, 128)       0           average_pooling1d_16[0][0]       \n",
      "                                                                 conv1d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_66 (Conv1D)              (None, 2, 128)       32896       add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_67 (Conv1D)              (None, 2, 128)       32896       add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_17 (Multiply)          (None, 2, 128)       0           conv1d_66[0][0]                  \n",
      "                                                                 conv1d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_17 (AveragePo (None, 2, 128)       0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_69 (Conv1D)              (None, 2, 128)       16512       multiply_17[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 2, 128)       0           average_pooling1d_17[0][0]       \n",
      "                                                                 conv1d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_70 (Conv1D)              (None, 1, 128)       32896       add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_71 (Conv1D)              (None, 1, 128)       32896       add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_18 (Multiply)          (None, 1, 128)       0           conv1d_70[0][0]                  \n",
      "                                                                 conv1d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 75000, 128)   16512       multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 37500, 128)   16512       multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 18750, 128)   16512       multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 9375, 128)    16512       multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 4688, 128)    16512       multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 2344, 128)    16512       multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 1172, 128)    16512       multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 586, 128)     16512       multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 293, 128)     16512       multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 147, 128)     16512       multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 74, 128)      16512       multiply_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 37, 128)      16512       multiply_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 19, 128)      16512       multiply_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 10, 128)      16512       multiply_14[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 5, 128)       16512       multiply_15[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 3, 128)       16512       multiply_16[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_68 (Conv1D)              (None, 2, 128)       16512       multiply_17[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_72 (Conv1D)              (None, 1, 128)       16512       multiply_18[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1, 128)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1, 128)       0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1, 128)       0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1, 128)       0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1, 128)       0           conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1, 128)       0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1, 128)       0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1, 128)       0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1, 128)       0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1, 128)       0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1, 128)       0           conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1, 128)       0           conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1, 128)       0           conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1, 128)       0           conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 1, 128)       0           conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 1, 128)       0           conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 1, 128)       0           conv1d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 1, 128)       0           conv1d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 1, 128)       0           lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "                                                                 lambda_10[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "                                                                 lambda_12[0][0]                  \n",
      "                                                                 lambda_13[0][0]                  \n",
      "                                                                 lambda_14[0][0]                  \n",
      "                                                                 lambda_15[0][0]                  \n",
      "                                                                 lambda_16[0][0]                  \n",
      "                                                                 lambda_17[0][0]                  \n",
      "                                                                 lambda_18[0][0]                  \n",
      "                                                                 lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1, 128)       0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_74 (Conv1D)              (None, 1, 128)       16512       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_75 (Conv1D)              (None, 1, 1)         129         conv1d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1)            0           conv1d_75[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,779,073\n",
      "Trainable params: 1,779,073\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "166/166 [==============================] - 161s 968ms/step - loss: 2.8445\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.84453, saving model to model_conv.h5\n",
      "Epoch 2/100\n",
      "166/166 [==============================] - 147s 884ms/step - loss: 2.6854\n",
      "\n",
      "Epoch 00002: loss improved from 2.84453 to 2.68542, saving model to model_conv.h5\n",
      "Epoch 3/100\n",
      "166/166 [==============================] - 147s 884ms/step - loss: 2.5070\n",
      "\n",
      "Epoch 00003: loss improved from 2.68542 to 2.50698, saving model to model_conv.h5\n",
      "Epoch 4/100\n",
      "166/166 [==============================] - 147s 884ms/step - loss: 2.4143\n",
      "\n",
      "Epoch 00004: loss improved from 2.50698 to 2.41431, saving model to model_conv.h5\n",
      "Epoch 5/100\n",
      "166/166 [==============================] - 147s 884ms/step - loss: 2.3274\n",
      "\n",
      "Epoch 00005: loss improved from 2.41431 to 2.32737, saving model to model_conv.h5\n",
      "Epoch 6/100\n",
      "166/166 [==============================] - 147s 884ms/step - loss: 2.2717\n",
      "\n",
      "Epoch 00006: loss improved from 2.32737 to 2.27173, saving model to model_conv.h5\n",
      "Epoch 7/100\n",
      "166/166 [==============================] - 147s 884ms/step - loss: 2.2793\n",
      "\n",
      "Epoch 00007: loss did not improve from 2.27173\n",
      "Epoch 8/100\n",
      "166/166 [==============================] - 147s 884ms/step - loss: 2.2648\n",
      "\n",
      "Epoch 00008: loss improved from 2.27173 to 2.26477, saving model to model_conv.h5\n",
      "Epoch 9/100\n",
      "166/166 [==============================] - 147s 884ms/step - loss: 2.2150\n",
      "\n",
      "Epoch 00009: loss improved from 2.26477 to 2.21502, saving model to model_conv.h5\n",
      "Epoch 10/100\n",
      "166/166 [==============================] - 147s 884ms/step - loss: 2.1923\n",
      "\n",
      "Epoch 00010: loss improved from 2.21502 to 2.19226, saving model to model_conv.h5\n",
      "Epoch 11/100\n",
      "166/166 [==============================] - 147s 884ms/step - loss: 2.2017\n",
      "\n",
      "Epoch 00011: loss did not improve from 2.19226\n",
      "Epoch 12/100\n",
      "166/166 [==============================] - 147s 884ms/step - loss: 2.2674\n",
      "\n",
      "Epoch 00012: loss did not improve from 2.19226\n",
      "Epoch 13/100\n",
      "166/166 [==============================] - 147s 884ms/step - loss: 2.2014\n",
      "\n",
      "Epoch 00013: loss did not improve from 2.19226\n",
      "Epoch 14/100\n",
      "166/166 [==============================] - 147s 884ms/step - loss: 2.1869\n",
      "\n",
      "Epoch 00014: loss improved from 2.19226 to 2.18689, saving model to model_conv.h5\n",
      "Epoch 15/100\n",
      "166/166 [==============================] - 147s 884ms/step - loss: 2.2013\n",
      "\n",
      "Epoch 00015: loss did not improve from 2.18689\n",
      "Epoch 16/100\n",
      "166/166 [==============================] - 147s 883ms/step - loss: 2.1694\n",
      "\n",
      "Epoch 00016: loss improved from 2.18689 to 2.16941, saving model to model_conv.h5\n",
      "Epoch 17/100\n",
      "166/166 [==============================] - 147s 884ms/step - loss: 2.1306\n",
      "\n",
      "Epoch 00017: loss improved from 2.16941 to 2.13057, saving model to model_conv.h5\n",
      "Epoch 18/100\n",
      "166/166 [==============================] - 147s 884ms/step - loss: 2.1866\n",
      "\n",
      "Epoch 00018: loss did not improve from 2.13057\n",
      "Epoch 19/100\n",
      "166/166 [==============================] - 147s 884ms/step - loss: 2.1861\n",
      "\n",
      "Epoch 00019: loss did not improve from 2.13057\n",
      "Epoch 20/100\n",
      "166/166 [==============================] - 147s 884ms/step - loss: 2.1459\n",
      "\n",
      "Epoch 00020: loss did not improve from 2.13057\n",
      "Epoch 21/100\n",
      "166/166 [==============================] - 147s 884ms/step - loss: 2.1581\n",
      "\n",
      "Epoch 00021: loss did not improve from 2.13057\n",
      "Epoch 22/100\n",
      "166/166 [==============================] - 147s 884ms/step - loss: 2.1344\n",
      "\n",
      "Epoch 00022: loss did not improve from 2.13057\n",
      "Epoch 23/100\n",
      "166/166 [==============================] - 147s 884ms/step - loss: 2.1134\n",
      "\n",
      "Epoch 00023: loss improved from 2.13057 to 2.11344, saving model to model_conv.h5\n",
      "Epoch 24/100\n",
      "166/166 [==============================] - 147s 884ms/step - loss: 2.1674\n",
      "\n",
      "Epoch 00024: loss did not improve from 2.11344\n",
      "Epoch 25/100\n",
      "166/166 [==============================] - 147s 883ms/step - loss: 2.1502\n",
      "\n",
      "Epoch 00025: loss did not improve from 2.11344\n",
      "Epoch 26/100\n",
      "166/166 [==============================] - 146s 882ms/step - loss: 2.1694\n",
      "\n",
      "Epoch 00026: loss did not improve from 2.11344\n",
      "Epoch 27/100\n",
      "166/166 [==============================] - 146s 882ms/step - loss: 2.1555\n",
      "\n",
      "Epoch 00027: loss did not improve from 2.11344\n",
      "Epoch 28/100\n",
      "166/166 [==============================] - 146s 880ms/step - loss: 2.1446\n",
      "\n",
      "Epoch 00028: loss did not improve from 2.11344\n",
      "Epoch 29/100\n",
      "166/166 [==============================] - 146s 880ms/step - loss: 2.1694\n",
      "\n",
      "Epoch 00029: loss did not improve from 2.11344\n",
      "Epoch 30/100\n",
      "166/166 [==============================] - 146s 880ms/step - loss: 2.1176\n",
      "\n",
      "Epoch 00030: loss did not improve from 2.11344\n",
      "Epoch 31/100\n",
      "166/166 [==============================] - 146s 881ms/step - loss: 2.1517\n",
      "\n",
      "Epoch 00031: loss did not improve from 2.11344\n",
      "Epoch 32/100\n",
      "166/166 [==============================] - 146s 881ms/step - loss: 2.1492\n",
      "\n",
      "Epoch 00032: loss did not improve from 2.11344\n",
      "Epoch 33/100\n",
      "166/166 [==============================] - 146s 882ms/step - loss: 2.1637\n",
      "\n",
      "Epoch 00033: loss did not improve from 2.11344\n",
      "Epoch 00033: early stopping\n"
     ]
    }
   ],
   "source": [
    "rez = train_model(128, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.12 - relu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.844535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.685416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.506978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.414309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.327375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.271727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.279340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.264768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.215024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.192257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.201673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.267358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.201442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.186894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.201346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.169412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.130569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.186601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.186085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.145937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.158094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.134392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.113443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.167413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.150238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.169353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.155503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.144602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.169370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.117611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2.151653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2.149198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.163657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss\n",
       "0   2.844535\n",
       "1   2.685416\n",
       "2   2.506978\n",
       "3   2.414309\n",
       "4   2.327375\n",
       "5   2.271727\n",
       "6   2.279340\n",
       "7   2.264768\n",
       "8   2.215024\n",
       "9   2.192257\n",
       "10  2.201673\n",
       "11  2.267358\n",
       "12  2.201442\n",
       "13  2.186894\n",
       "14  2.201346\n",
       "15  2.169412\n",
       "16  2.130569\n",
       "17  2.186601\n",
       "18  2.186085\n",
       "19  2.145937\n",
       "20  2.158094\n",
       "21  2.134392\n",
       "22  2.113443\n",
       "23  2.167413\n",
       "24  2.150238\n",
       "25  2.169353\n",
       "26  2.155503\n",
       "27  2.144602\n",
       "28  2.169370\n",
       "29  2.117611\n",
       "30  2.151653\n",
       "31  2.149198\n",
       "32  2.163657"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rez.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8ee44606a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(rez.history).plot(figsize=(16, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a494cfcb7474e6fae14e2be781e8699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2624), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = models.load_model(\"model_conv.h5\")\n",
    "submission = pd.read_csv(\n",
    "    \"../input/sample_submission.csv\", \n",
    "    index_col='seg_id', \n",
    "    dtype={'time_to_failure': np.float32}\n",
    ")\n",
    "for seg_id in tqdm_notebook(submission.index):\n",
    "    seg = pd.read_csv(f\"../input/test/{seg_id}.csv\")\n",
    "    X = seg[\"acoustic_data\"].values.reshape(1, TEST_SIZE, 1)\n",
    "    y = model.predict(X)\n",
    "    submission.loc[seg_id][\"time_to_failure\"] = y\n",
    "submission.to_csv(f\"submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
